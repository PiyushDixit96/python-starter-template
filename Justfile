set shell := ["zsh"]

# include development-specific requirements here
requirements:
# for procfile management
	@if ! gem list -i foreman >/dev/null 2>&1; then \
		echo "Installing foreman"; \
		gem install foreman; \
	fi

	@if ! which direnv > /dev/null; then \
			echo "direnv is not installed. Please install."; \
			exit 1; \
	fi

upgrade:
	echo "Include any upgrade commands here"


setup: requirements
	cp .env.local-example .env.local
	direnv allow .

	cat .tool-versions | cut -d' ' -f1 | grep '^[^\#]' | xargs -I{} asdf plugin add {}
	asdf install

	# for better asdf compatibility; config updates writes to: ~/Library/Preferences/pypoetry/config.toml
	poetry config virtualenvs.in-project true
	poetry config virtualenvs.prefer-active-python true
	poetry install

	$(MAKE) db-reset

	bin/metabase_setup.sh

up:
	$(MAKE) redis:up
	$(MAKE) db:up

# TODO `op` should be locked to a specific account in some way

#######################
# Linting & Static Analysis
#######################

# lint:
# 	poetry run black .
# 	poetry run isort .
# 	poetry run autoflake --exclude=migrations --imports=decouple,rich -i -r .
# 	poetry run flake8 .
# 	poetry run deptry .

#######################
# Redis
#######################

redis:up:
	docker compose up --wait -d redis

#######################
# Database Migrations
#######################

db:up:
	docker compose up -d --wait postgres

db:reset:
	docker compose down --volumes postgres
	$(MAKE) db:up
	psql $$DATABASE_URL -c "CREATE DATABASE test;"

db:migrate:
	alembic upgrade head
	PYTHON_ENV=test alembic upgrade head

db:seed: db:migrate
	python migrations/seed.py
	PYTHON_ENV=test python migrations/seed.py

db:generate:migration:
	@if [ -z "$${MIGRATION_NAME}" ]; then \
		echo "Enter the migration name: "; \
		read name; \
	else \
		name=$${MIGRATION_NAME}; \
	fi; \

	alembic revision --autogenerate -m "$$name"

# destroy and rebuild the database from the ground up
# less intense than nuking the, keeps existing migrations
db:destroy:
	$(MAKE) db:reset
	$(MAKE) db:migrate
	$(MAKE) db:seed

# only for use in early development :)
db:nuke:
	$(MAKE) db:reset

	# destroy existing migrations, this is a terrible idea except when you are hacking :)
	rm -rf migrations/versions/* || true
	$(MAKE) db:generate:migration MIGRATION_NAME="initial_commit"

	$(MAKE) db:migrate
	$(MAKE) db:seed

	PYTHON_ENV=test $(MAKE) db:migrate
	PYTHON_ENV=test $(MAKE) db:seed

#######################
# Production Build
#######################

IMAGE_NAME ?= "app"
IMAGE_TAG ?= "latest"
# TODO should pull from .env.production
BUILD_CMD = nixpacks build . --name $(IMAGE_NAME) --tag $(IMAGE_TAG)

deploy:
	if ! git remote | grep -q dokku; then \
		git remote add dokku dokku@dokku.me:app; \
	fi

	git push dokku main

# build the docker container using nixpacks
build:
	$(BUILD_CMD)

# dump nixpacks-generated Dockerfile for manual build and production debugging
build:dump:
	$(BUILD_CMD) --out .

# inject a shell where the build fails
build:debug:
	BUILDX_EXPERIMENTAL=1 docker buildx debug --invoke bash build . -f ./.nixpacks/Dockerfile

# instead of using autogenerated Dockerfile, build from the dumped Dockerfile which can be manually modified
build:from-dump:
	# docker build . -f ./.nixpacks/Dockerfile -t $(IMAGE_NAME):$(IMAGE_TAG)
	$(SHELL) .nixpacks/build.sh

# open up a bash shell in the last built container, helpful for debugging production builds
build:shell:
# TODO should check if image exists and build if it doesn't
	docker run -it $(IMAGE_NAME):$(IMAGE_TAG) bash -l

# open up a *second* shell in the *same* container that's already running
build:shell-exec:
	docker exec -it $(shell docker ps -q -f ancestor=$(IMAGE_NAME):$(IMAGE_TAG)) bash -l

# run the container locally, as if it were in production (against production DB, resources, etc)
build:run-as-production:
# TODO I don't think we want ulimit here, that's just for core dumps, which doesn't seem to work
	docker run --ulimit core=-1 --network=host -e LOG_LEVEL=DEBUG -e DATABASE_URL="$$DATABASE_URL" -e REDIS_URL="$$REDIS_URL" -e OPENAI_API_KEY="$$OPENAI_API_KEY" -e SENTRY_DSN="" $(IMAGE_NAME):$(IMAGE_TAG)

clean:
	rm -rf .nixpacks
	rm -r tmp/*